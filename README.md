# Системе подсчета пользовательских транзакций

## Описание архитектуры

Сервис состоит из API и хранилища транзакций.

Хранилище транзакций представляет базу данных ClickHouse, логика подсчета реализуется при помощи встроенных средств БД.

API реализует два метода:
* `/saveTransacction`
* `/getCountByPattern`

## Хранилище транзакций
Представляет из себя кластер ClickHouse.

Транзакции хранятся в таблице, каждый параметр транзакции - столбец в БД.

## API

API представляет из себя сервис для доступа к БД, протокол и формат данных (REST/gRPC/JSON) значения не имеют (можно выбрать подходящий после тестов)

Метод `/saveTransaction` принимает на вход данные о транзакции, после чего преобразует его к INSERT-запросу в базу и выполняет его

Метод `/getCountByPattern` принимает на вход паттерн, после чего преобразует его к аггрегирующему (COUNT) запросу SELECT из таблицы транзакций.

Сервис API запущен в нескольких экземплярах, роутинг осуществляется через nginx.

## Требования к системе, возможные проблемы и решения
Список обрабатываемых паттернов может меняться / дополняться

     Паттерны не хранятся в системе, спецификация запроса передается в API при выборке данных для большей гибкости.

     Если набор паттернов ограничен и обновляется редко и в ручном режиме (например, по данным транзцакций строятся различные графики для финансовой аналитики), то возможно имеет смысл каждый паттерн сохранить непосредственно в БД в качестве MATERIALIZED VIEW и не использовать метод getCountByPattern)

Нужна возможность получать исторические данные, о результате подсчета по определенной транзакции
    
    Имеется возможность получать любые данные за любой промежуток времени, заданием необходимого временного интервала в паттерне

Пропускная способность системы должны быть 100 rps (средняя нагрузка ~20rps)
    Потенциально, такая система может обрабатывать >10krps, далее можно горизонтально масштабироваться за счет увеличения количества инстансов API
    
    Количество записей в таблице (оценка сверху)  3_153_600_000

Система должна выносить решение <= 1s по 99 персентилю

    * Чтение данных (то есть основной функционал сервиса - подсчет транзакций) (метод `/getCountByPattern`)
    
        СУБД ClickHouse позволяет получать результат агрегирующей функции по условию, на объёмах порядка 1 миллиард за сотые доли секунды (по данным бенчмарка https://clickhouse.tech/benchmark/dbms/)
    
    * Запись данных
    
        При обработке записи транзакций в API при синхронной записи данных в БД (on hit) возможны задержки в виду особенностей архитектуры выбранной СУБД (Не рекомендуется делать одиночные INSERT в таблицу).
    
        Возможные решения проблемы:
        
            * Агрегироваанние данных на стороне HTTP server (API)
              При получении запроса, данные собираются в пачку (batch), агреггирование идёт по двум параметрам - количество транзакций в пачке и время агреггирования. Запрос выполняется в БД при выполнении одного из условий (сработал таймер или набралось минимальное количество запросов). Параметры агреггирования (по умолчанию, например, 500ms и 1000 транзакций) можно настраивать и подбирать оптимальные в процессе эксплуатации системы.

            * Полностью асинхронная запись. 
              API принимает запрос на сохранение транзакции, проводит первичную валидацию (обязательные поля, типы данных и т.п.), после чего отдает ответ клиенту (HTTP Response) и складывает данные о транзакции в сервис очередей (например, RabbitMQ)
              Далее, отдельный демон в фоновом режиме читает запросы из очереди, аггрегирует их и отправляет запросы на вставку.
              
              При таком сценарии ответ и на чтение и на запись в API будет гарантированно отдаваться в течение одной секунды, однако возможны проблемы с консистентностью (при запросе `/saveTransaction` и сразу же запросе на получение данных по паттерну, который должен был измениться в результате этой транзакции, могут вернуться неактуальные данные, если транзакция не успела обработаться и добавиться в качестве записи в таблицу в БД)
              
            * При нагрузках до 100rps и известном заранее списке паттернов, все транзакции, попадающие в тот или иной паттерн можно хранить непосредственно в памяти, например с использованием Redis Sorted Set (каждый паттерн - отдельный Set в Redis, ключом сортировки выступает время транзакции). 
              Таким образом, при получении новой транзакции, можно проверить её на соответствие каждому паттерну по набору условий, после чего добавить транзакцию в соответствующий Sorted Set.
              Для получения количества транзакций, попадающих в тот или иной паттерн, достаточно одного обращения к Redis (ZRANGEBYSCORE)
              
              При этом, поскольку быстрый доступ необходим только в диапазоне 1 месяца, можно скомбинировать это решение с постоянным хранилищем в ClickHouse (при получении запроса в пределах месяца - получаем данные из Redis, в противном случае - из ClickHouse) 
